services:
  llama-cpp:
    build:
      context: .
      dockerfile: Dockerfile
    volumes:
      - ../model:/app/model
      - ../result:/app/result
      - ../tips:/app/tips
    environment:
      - OMP_NUM_THREADS=1
      - OPENBLAS_NUM_THREADS=1
    working_dir: /app/llama.cpp
    command: /bin/bash
